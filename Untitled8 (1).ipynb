{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxj2WozJ4u59",
        "outputId": "a8d5ab6c-64a5-4b3c-bc29-ef33cbdc2ad8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.10.0-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2023.7.22)\n",
            "Installing collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.10.0\n"
          ]
        }
      ],
      "source": [
        "!pip install SpeechRecognition"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the scipy version packaged with colab is not tolerant of misformated WAV files.\n",
        "# install the latest version.\n",
        "!pip3 install -U scipy\n",
        "\n",
        "!git clone https://github.com/jnordberg/tortoise-tts.git\n",
        "%cd tortoise-tts\n",
        "!pip3 install -r requirements.txt\n",
        "!pip3 install transformers==4.19.0 einops==0.5.0 rotary_embedding_torch==0.1.5 unidecode==1.3.5\n",
        "!python3 setup.py install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uH2CUsZnT6oN",
        "outputId": "5fd95f8a-aa3a-4d4d-8904-47f7238ff6a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.2)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.23.5)\n",
            "Cloning into 'tortoise-tts'...\n",
            "remote: Enumerating objects: 1481, done.\u001b[K\n",
            "remote: Total 1481 (delta 0), reused 0 (delta 0), pack-reused 1481\u001b[K\n",
            "Receiving objects: 100% (1481/1481), 53.56 MiB | 22.55 MiB/s, done.\n",
            "Resolving deltas: 100% (604/604), done.\n",
            "/content/tortoise-tts\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (4.66.1)\n",
            "Collecting rotary_embedding_torch (from -r requirements.txt (line 2))\n",
            "  Downloading rotary_embedding_torch-0.3.0-py3-none-any.whl (4.9 kB)\n",
            "Collecting transformers (from -r requirements.txt (line 3))\n",
            "  Downloading transformers-4.33.1-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers (from -r requirements.txt (line 4))\n",
            "  Downloading tokenizers-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (7.0.0)\n",
            "Collecting progressbar (from -r requirements.txt (line 6))\n",
            "  Downloading progressbar-2.5.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting einops (from -r requirements.txt (line 7))\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unidecode (from -r requirements.txt (line 8))\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (1.11.2)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (0.10.1)\n",
            "Collecting numba==0.48.0 (from -r requirements.txt (line 11))\n",
            "  Downloading numba-0.48.0.tar.gz (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ffmpeg (from -r requirements.txt (line 12))\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting llvmlite<0.32.0,>=0.31.0dev0 (from numba==0.48.0->-r requirements.txt (line 11))\n",
            "  Downloading llvmlite-0.31.0.tar.gz (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from numba==0.48.0->-r requirements.txt (line 11)) (1.23.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba==0.48.0->-r requirements.txt (line 11)) (67.7.2)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from rotary_embedding_torch->-r requirements.txt (line 2)) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 3)) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers->-r requirements.txt (line 3))\n",
            "  Downloading huggingface_hub-0.17.1-py3-none-any.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.8/294.8 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 3)) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 3)) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 3)) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 3)) (2.31.0)\n",
            "Collecting tokenizers (from -r requirements.txt (line 4))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers->-r requirements.txt (line 3))\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from inflect->-r requirements.txt (line 5)) (1.10.12)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from inflect->-r requirements.txt (line 5)) (4.5.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 10)) (3.0.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 10)) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 10)) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 10)) (4.4.2)\n",
            "INFO: pip is looking at multiple versions of librosa to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting librosa (from -r requirements.txt (line 10))\n",
            "  Downloading librosa-0.10.0.post2-py3-none-any.whl (253 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading librosa-0.10.0.post1-py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading librosa-0.10.0-py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.9/252.9 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading librosa-0.9.2-py3-none-any.whl (214 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.3/214.3 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting resampy>=0.2.2 (from librosa->-r requirements.txt (line 10))\n",
            "  Downloading resampy-0.4.2-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 10)) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 10)) (1.7.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers->-r requirements.txt (line 3)) (2023.6.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa->-r requirements.txt (line 10)) (3.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 3)) (2023.7.22)\n",
            "INFO: pip is looking at multiple versions of resampy to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading resampy-0.4.1-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading resampy-0.4.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading resampy-0.3.1-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa->-r requirements.txt (line 10)) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.10.2->librosa->-r requirements.txt (line 10)) (1.15.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->rotary_embedding_torch->-r requirements.txt (line 2)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->rotary_embedding_torch->-r requirements.txt (line 2)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->rotary_embedding_torch->-r requirements.txt (line 2)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->rotary_embedding_torch->-r requirements.txt (line 2)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6->rotary_embedding_torch->-r requirements.txt (line 2)) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6->rotary_embedding_torch->-r requirements.txt (line 2)) (16.0.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa->-r requirements.txt (line 10)) (2.21)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->rotary_embedding_torch->-r requirements.txt (line 2)) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->rotary_embedding_torch->-r requirements.txt (line 2)) (1.3.0)\n",
            "Building wheels for collected packages: numba, progressbar, ffmpeg, llvmlite\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for numba (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for numba\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for numba\n",
            "  Building wheel for progressbar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progressbar: filename=progressbar-2.5-py3-none-any.whl size=12067 sha256=63c8458e32d0bc2b7c34725ecb58867121526a60f5be7b7214424c923c6398b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/17/e5/765d1a3112ff3978f70223502f6047e06c43a24d7c5f8ff95b\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6082 sha256=95ec5138e80d7cdc9b1b2299f5e33d95e37ad01780d676300a9fc4225529dd58\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for llvmlite (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for llvmlite\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for llvmlite\n",
            "Successfully built progressbar ffmpeg\n",
            "Failed to build numba llvmlite\n",
            "\u001b[31mERROR: Could not build wheels for numba, llvmlite, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting transformers==4.19.0\n",
            "  Downloading transformers-4.19.0-py3-none-any.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops==0.5.0\n",
            "  Downloading einops-0.5.0-py3-none-any.whl (36 kB)\n",
            "Collecting rotary_embedding_torch==0.1.5\n",
            "  Downloading rotary_embedding_torch-0.1.5-py3-none-any.whl (4.1 kB)\n",
            "Collecting unidecode==1.3.5\n",
            "  Downloading Unidecode-1.3.5-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.5/236.5 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.0) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0 (from transformers==4.19.0)\n",
            "  Using cached huggingface_hub-0.17.1-py3-none-any.whl (294 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.0) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.0) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1 (from transformers==4.19.0)\n",
            "  Downloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.0) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from rotary_embedding_torch==0.1.5) (2.0.1+cu118)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.19.0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.19.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->rotary_embedding_torch==0.1.5) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->rotary_embedding_torch==0.1.5) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->rotary_embedding_torch==0.1.5) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->rotary_embedding_torch==0.1.5) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6->rotary_embedding_torch==0.1.5) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6->rotary_embedding_torch==0.1.5) (16.0.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.19.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.19.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.19.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.19.0) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->rotary_embedding_torch==0.1.5) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->rotary_embedding_torch==0.1.5) (1.3.0)\n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'unidecode' candidate (version 1.3.5 at https://files.pythonhosted.org/packages/7c/bb/a1cea9ce56434cdb59cb4c8b7bf91b190011b7000fb0a12b44fa0a3daa86/Unidecode-1.3.5-py3-none-any.whl (from https://pypi.org/simple/unidecode/) (requires-python:>=3.5))\n",
            "Reason for being yanked: wrong version of the code was released in the .whl package\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: tokenizers, unidecode, einops, huggingface-hub, transformers, rotary_embedding_torch\n",
            "Successfully installed einops-0.5.0 huggingface-hub-0.17.1 rotary_embedding_torch-0.1.5 tokenizers-0.12.1 transformers-4.19.0 unidecode-1.3.5\n",
            "running install\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating TorToiSe.egg-info\n",
            "writing TorToiSe.egg-info/PKG-INFO\n",
            "writing dependency_links to TorToiSe.egg-info/dependency_links.txt\n",
            "writing requirements to TorToiSe.egg-info/requires.txt\n",
            "writing top-level names to TorToiSe.egg-info/top_level.txt\n",
            "writing manifest file 'TorToiSe.egg-info/SOURCES.txt'\n",
            "reading manifest file 'TorToiSe.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'TorToiSe.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/tortoise\n",
            "copying tortoise/get_conditioning_latents.py -> build/lib/tortoise\n",
            "copying tortoise/api.py -> build/lib/tortoise\n",
            "copying tortoise/read.py -> build/lib/tortoise\n",
            "copying tortoise/do_tts.py -> build/lib/tortoise\n",
            "copying tortoise/eval.py -> build/lib/tortoise\n",
            "copying tortoise/is_this_from_tortoise.py -> build/lib/tortoise\n",
            "copying tortoise/__init__.py -> build/lib/tortoise\n",
            "creating build/lib/tortoise/utils\n",
            "copying tortoise/utils/text.py -> build/lib/tortoise/utils\n",
            "copying tortoise/utils/tokenizer.py -> build/lib/tortoise/utils\n",
            "copying tortoise/utils/stft.py -> build/lib/tortoise/utils\n",
            "copying tortoise/utils/samples_generator.py -> build/lib/tortoise/utils\n",
            "copying tortoise/utils/wav2vec_alignment.py -> build/lib/tortoise/utils\n",
            "copying tortoise/utils/audio.py -> build/lib/tortoise/utils\n",
            "copying tortoise/utils/typical_sampling.py -> build/lib/tortoise/utils\n",
            "copying tortoise/utils/diffusion.py -> build/lib/tortoise/utils\n",
            "copying tortoise/utils/__init__.py -> build/lib/tortoise/utils\n",
            "creating build/lib/tortoise/models\n",
            "copying tortoise/models/transformer.py -> build/lib/tortoise/models\n",
            "copying tortoise/models/random_latent_generator.py -> build/lib/tortoise/models\n",
            "copying tortoise/models/autoregressive.py -> build/lib/tortoise/models\n",
            "copying tortoise/models/arch_util.py -> build/lib/tortoise/models\n",
            "copying tortoise/models/clvp.py -> build/lib/tortoise/models\n",
            "copying tortoise/models/diffusion_decoder.py -> build/lib/tortoise/models\n",
            "copying tortoise/models/cvvp.py -> build/lib/tortoise/models\n",
            "copying tortoise/models/xtransformers.py -> build/lib/tortoise/models\n",
            "copying tortoise/models/classifier.py -> build/lib/tortoise/models\n",
            "copying tortoise/models/vocoder.py -> build/lib/tortoise/models\n",
            "copying tortoise/models/__init__.py -> build/lib/tortoise/models\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/tortoise\n",
            "copying build/lib/tortoise/get_conditioning_latents.py -> build/bdist.linux-x86_64/egg/tortoise\n",
            "copying build/lib/tortoise/api.py -> build/bdist.linux-x86_64/egg/tortoise\n",
            "copying build/lib/tortoise/read.py -> build/bdist.linux-x86_64/egg/tortoise\n",
            "copying build/lib/tortoise/do_tts.py -> build/bdist.linux-x86_64/egg/tortoise\n",
            "copying build/lib/tortoise/eval.py -> build/bdist.linux-x86_64/egg/tortoise\n",
            "creating build/bdist.linux-x86_64/egg/tortoise/utils\n",
            "copying build/lib/tortoise/utils/text.py -> build/bdist.linux-x86_64/egg/tortoise/utils\n",
            "copying build/lib/tortoise/utils/tokenizer.py -> build/bdist.linux-x86_64/egg/tortoise/utils\n",
            "copying build/lib/tortoise/utils/stft.py -> build/bdist.linux-x86_64/egg/tortoise/utils\n",
            "copying build/lib/tortoise/utils/samples_generator.py -> build/bdist.linux-x86_64/egg/tortoise/utils\n",
            "copying build/lib/tortoise/utils/wav2vec_alignment.py -> build/bdist.linux-x86_64/egg/tortoise/utils\n",
            "copying build/lib/tortoise/utils/audio.py -> build/bdist.linux-x86_64/egg/tortoise/utils\n",
            "copying build/lib/tortoise/utils/typical_sampling.py -> build/bdist.linux-x86_64/egg/tortoise/utils\n",
            "copying build/lib/tortoise/utils/diffusion.py -> build/bdist.linux-x86_64/egg/tortoise/utils\n",
            "copying build/lib/tortoise/utils/__init__.py -> build/bdist.linux-x86_64/egg/tortoise/utils\n",
            "copying build/lib/tortoise/is_this_from_tortoise.py -> build/bdist.linux-x86_64/egg/tortoise\n",
            "copying build/lib/tortoise/__init__.py -> build/bdist.linux-x86_64/egg/tortoise\n",
            "creating build/bdist.linux-x86_64/egg/tortoise/models\n",
            "copying build/lib/tortoise/models/transformer.py -> build/bdist.linux-x86_64/egg/tortoise/models\n",
            "copying build/lib/tortoise/models/random_latent_generator.py -> build/bdist.linux-x86_64/egg/tortoise/models\n",
            "copying build/lib/tortoise/models/autoregressive.py -> build/bdist.linux-x86_64/egg/tortoise/models\n",
            "copying build/lib/tortoise/models/arch_util.py -> build/bdist.linux-x86_64/egg/tortoise/models\n",
            "copying build/lib/tortoise/models/clvp.py -> build/bdist.linux-x86_64/egg/tortoise/models\n",
            "copying build/lib/tortoise/models/diffusion_decoder.py -> build/bdist.linux-x86_64/egg/tortoise/models\n",
            "copying build/lib/tortoise/models/cvvp.py -> build/bdist.linux-x86_64/egg/tortoise/models\n",
            "copying build/lib/tortoise/models/xtransformers.py -> build/bdist.linux-x86_64/egg/tortoise/models\n",
            "copying build/lib/tortoise/models/classifier.py -> build/bdist.linux-x86_64/egg/tortoise/models\n",
            "copying build/lib/tortoise/models/vocoder.py -> build/bdist.linux-x86_64/egg/tortoise/models\n",
            "copying build/lib/tortoise/models/__init__.py -> build/bdist.linux-x86_64/egg/tortoise/models\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/get_conditioning_latents.py to get_conditioning_latents.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/api.py to api.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/read.py to read.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/do_tts.py to do_tts.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/eval.py to eval.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/utils/text.py to text.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/utils/tokenizer.py to tokenizer.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/utils/stft.py to stft.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/utils/samples_generator.py to samples_generator.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/utils/wav2vec_alignment.py to wav2vec_alignment.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/utils/audio.py to audio.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/utils/typical_sampling.py to typical_sampling.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/utils/diffusion.py to diffusion.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/utils/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/is_this_from_tortoise.py to is_this_from_tortoise.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/models/transformer.py to transformer.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/models/random_latent_generator.py to random_latent_generator.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/models/autoregressive.py to autoregressive.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/models/arch_util.py to arch_util.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/models/clvp.py to clvp.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/models/diffusion_decoder.py to diffusion_decoder.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/models/cvvp.py to cvvp.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/models/xtransformers.py to xtransformers.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/models/classifier.py to classifier.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/models/vocoder.py to vocoder.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tortoise/models/__init__.py to __init__.cpython-310.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying TorToiSe.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying TorToiSe.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying TorToiSe.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying TorToiSe.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying TorToiSe.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/TorToiSe-2.3.0-py3.10.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing TorToiSe-2.3.0-py3.10.egg\n",
            "Copying TorToiSe-2.3.0-py3.10.egg to /usr/local/lib/python3.10/dist-packages\n",
            "Adding TorToiSe 2.3.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/TorToiSe-2.3.0-py3.10.egg\n",
            "Processing dependencies for TorToiSe==2.3.0\n",
            "Searching for progressbar\n",
            "Reading https://pypi.org/simple/progressbar/\n",
            "Downloading https://files.pythonhosted.org/packages/a3/a6/b8e451f6cff1c99b4747a2f7235aa904d2d49e8e1464e0b798272aa84358/progressbar-2.5.tar.gz#sha256=5d81cb529da2e223b53962afd6c8ca0f05c6670e40309a7219eacc36af9b6c63\n",
            "Best match: progressbar 2.5\n",
            "Processing progressbar-2.5.tar.gz\n",
            "Writing /tmp/easy_install-_7c3w3a4/progressbar-2.5/setup.cfg\n",
            "Running progressbar-2.5/setup.py -q bdist_egg --dist-dir /tmp/easy_install-_7c3w3a4/progressbar-2.5/egg-dist-tmp-8k_94lbi\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "Adding progressbar 2.5 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/progressbar-2.5-py3.10.egg\n",
            "Searching for tokenizers==0.12.1\n",
            "Best match: tokenizers 0.12.1\n",
            "Adding tokenizers 0.12.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for transformers==4.19.0\n",
            "Best match: transformers 4.19.0\n",
            "Adding transformers 4.19.0 to easy-install.pth file\n",
            "Installing transformers-cli script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for librosa==0.10.1\n",
            "Best match: librosa 0.10.1\n",
            "Adding librosa 0.10.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for scipy==1.11.2\n",
            "Best match: scipy 1.11.2\n",
            "Adding scipy 1.11.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for Unidecode==1.3.5\n",
            "Best match: Unidecode 1.3.5\n",
            "Adding Unidecode 1.3.5 to easy-install.pth file\n",
            "Installing unidecode script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for einops==0.5.0\n",
            "Best match: einops 0.5.0\n",
            "Adding einops 0.5.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for inflect==7.0.0\n",
            "Best match: inflect 7.0.0\n",
            "Adding inflect 7.0.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for rotary-embedding-torch==0.1.5\n",
            "Best match: rotary-embedding-torch 0.1.5\n",
            "Adding rotary-embedding-torch 0.1.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for tqdm==4.66.1\n",
            "Best match: tqdm 4.66.1\n",
            "Adding tqdm 4.66.1 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for requests==2.31.0\n",
            "Best match: requests 2.31.0\n",
            "Adding requests 2.31.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for regex==2023.6.3\n",
            "Best match: regex 2023.6.3\n",
            "Adding regex 2023.6.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for PyYAML==6.0.1\n",
            "Best match: PyYAML 6.0.1\n",
            "Adding PyYAML 6.0.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for packaging==23.1\n",
            "Best match: packaging 23.1\n",
            "Adding packaging 23.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for numpy==1.23.5\n",
            "Best match: numpy 1.23.5\n",
            "Adding numpy 1.23.5 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.10 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for huggingface-hub==0.17.1\n",
            "Best match: huggingface-hub 0.17.1\n",
            "Adding huggingface-hub 0.17.1 to easy-install.pth file\n",
            "Installing huggingface-cli script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for filelock==3.12.2\n",
            "Best match: filelock 3.12.2\n",
            "Adding filelock 3.12.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for msgpack==1.0.5\n",
            "Best match: msgpack 1.0.5\n",
            "Adding msgpack 1.0.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for lazy-loader==0.3\n",
            "Best match: lazy-loader 0.3\n",
            "Adding lazy-loader 0.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for typing-extensions==4.5.0\n",
            "Best match: typing-extensions 4.5.0\n",
            "Adding typing-extensions 4.5.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for soxr==0.3.6\n",
            "Best match: soxr 0.3.6\n",
            "Adding soxr 0.3.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for pooch==1.7.0\n",
            "Best match: pooch 1.7.0\n",
            "Adding pooch 1.7.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for soundfile==0.12.1\n",
            "Best match: soundfile 0.12.1\n",
            "Adding soundfile 0.12.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for numba==0.56.4\n",
            "Best match: numba 0.56.4\n",
            "Adding numba 0.56.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for decorator==4.4.2\n",
            "Best match: decorator 4.4.2\n",
            "Adding decorator 4.4.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for joblib==1.3.2\n",
            "Best match: joblib 1.3.2\n",
            "Adding joblib 1.3.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for scikit-learn==1.2.2\n",
            "Best match: scikit-learn 1.2.2\n",
            "Adding scikit-learn 1.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for audioread==3.0.0\n",
            "Best match: audioread 3.0.0\n",
            "Adding audioread 3.0.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for pydantic==1.10.12\n",
            "Best match: pydantic 1.10.12\n",
            "Adding pydantic 1.10.12 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for torch==2.0.1+cu118\n",
            "Best match: torch 2.0.1+cu118\n",
            "Adding torch 2.0.1+cu118 to easy-install.pth file\n",
            "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
            "Installing torchrun script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for certifi==2023.7.22\n",
            "Best match: certifi 2023.7.22\n",
            "Adding certifi 2023.7.22 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for urllib3==2.0.4\n",
            "Best match: urllib3 2.0.4\n",
            "Adding urllib3 2.0.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for idna==3.4\n",
            "Best match: idna 3.4\n",
            "Adding idna 3.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for charset-normalizer==3.2.0\n",
            "Best match: charset-normalizer 3.2.0\n",
            "Adding charset-normalizer 3.2.0 to easy-install.pth file\n",
            "Installing normalizer script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for fsspec==2023.6.0\n",
            "Best match: fsspec 2023.6.0\n",
            "Adding fsspec 2023.6.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for platformdirs==3.10.0\n",
            "Best match: platformdirs 3.10.0\n",
            "Adding platformdirs 3.10.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for cffi==1.15.1\n",
            "Best match: cffi 1.15.1\n",
            "Adding cffi 1.15.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for setuptools==67.7.2\n",
            "Best match: setuptools 67.7.2\n",
            "Adding setuptools 67.7.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for llvmlite==0.39.1\n",
            "Best match: llvmlite 0.39.1\n",
            "Adding llvmlite 0.39.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for threadpoolctl==3.2.0\n",
            "Best match: threadpoolctl 3.2.0\n",
            "Adding threadpoolctl 3.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for triton==2.0.0\n",
            "Best match: triton 2.0.0\n",
            "Adding triton 2.0.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for Jinja2==3.1.2\n",
            "Best match: Jinja2 3.1.2\n",
            "Adding Jinja2 3.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for networkx==3.1\n",
            "Best match: networkx 3.1\n",
            "Adding networkx 3.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for sympy==1.12\n",
            "Best match: sympy 1.12\n",
            "Adding sympy 1.12 to easy-install.pth file\n",
            "Installing isympy script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for pycparser==2.21\n",
            "Best match: pycparser 2.21\n",
            "Adding pycparser 2.21 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for lit==16.0.6\n",
            "Best match: lit 16.0.6\n",
            "Adding lit 16.0.6 to easy-install.pth file\n",
            "Installing lit script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for cmake==3.27.4.1\n",
            "Best match: cmake 3.27.4.1\n",
            "Adding cmake 3.27.4.1 to easy-install.pth file\n",
            "Installing cmake script to /usr/local/bin\n",
            "Installing cpack script to /usr/local/bin\n",
            "Installing ctest script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for MarkupSafe==2.1.3\n",
            "Best match: MarkupSafe 2.1.3\n",
            "Adding MarkupSafe 2.1.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for mpmath==1.3.0\n",
            "Best match: mpmath 1.3.0\n",
            "Adding mpmath 1.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Finished processing dependencies for TorToiSe==2.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "import speech_recognition as sr\n",
        "\n",
        "# Imports used through the rest of the notebook.\n",
        "import torch\n",
        "import torchaudio\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import IPython\n",
        "\n",
        "from tortoise.api import TextToSpeech\n",
        "from tortoise.utils.audio import load_audio, load_voice, load_voices\n"
      ],
      "metadata": {
        "id": "Ee3N4mv5T81E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# upload your wav file to extract the text"
      ],
      "metadata": {
        "id": "fbQXoQCxVLFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "VOICE_NAME = \"ahmed\"\n",
        "\n",
        "def main():\n",
        "    global texts ,sounds, audio\n",
        "    voice_folder = f\"/content/{VOICE_NAME}\"\n",
        "    if os.path.exists(voice_folder):\n",
        "\n",
        "      shutil.rmtree(voice_folder)\n",
        "\n",
        "    os.makedirs(voice_folder, exist_ok=True)\n",
        "    for i, file_data in enumerate(files.upload().values()):\n",
        "      with open(os.path.join(voice_folder, f'{i}.wav'), 'wb') as f:\n",
        "        f.write(file_data)\n",
        "    sound = f\"/content/{VOICE_NAME}/0.wav\"\n",
        "    sounds = f\"/content/{VOICE_NAME}/0.wav\"\n",
        "    r = sr.Recognizer()\n",
        "\n",
        "\n",
        "    with sr.AudioFile(sound) as source:\n",
        "        r.adjust_for_ambient_noise(source)\n",
        "\n",
        "\n",
        "        print(\"Converting Audio To Text ..... \")\n",
        "\n",
        "\n",
        "        audio = r.listen(source)\n",
        "\n",
        "    try:\n",
        "        texts = r.recognize_google(audio)\n",
        "        print(\"Converted Audio Is : \\n\" + texts)\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Error {} : \".format(e) )\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "TbjYCs4843ct",
        "outputId": "210ce3ff-d5eb-4120-d682-53143088ab8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-47e207e8-c4ac-430a-b1c6-d5d02d62841e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-47e207e8-c4ac-430a-b1c6-d5d02d62841e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving scm_05223_01449581873.wav to scm_05223_01449581873.wav\n",
            "Converting Audio To Text ..... \n",
            "Converted Audio Is : \n",
            "happy Good Friday\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sounds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hOi0MK47VN8i",
        "outputId": "e531131c-771d-4f1d-c7ee-3c575fe44ae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/ahmed/0.wav'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ddaK3mJg_nuI",
        "outputId": "04264b1c-456d-4c34-f991-7435cd53fb0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'happy Good Friday'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Enter the word that you want to be changed from the original text\n"
      ],
      "metadata": {
        "id": "bhFxIJbjVaU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_word(text, word_to_replace, replacement):\n",
        "    # Split the input text into words\n",
        "    words = text.split()\n",
        "\n",
        "    # Initialize an empty list to store the modified words\n",
        "    new_words = []\n",
        "\n",
        "    # Iterate through the words in the input text\n",
        "    for word in words:\n",
        "        # If the word matches the word to be replaced, use the replacement word\n",
        "        if word == word_to_replace:\n",
        "            new_words.append(replacement)\n",
        "        else:\n",
        "            new_words.append(word)\n",
        "\n",
        "    # Join the modified words to form the new text\n",
        "    new_text = \" \".join(new_words)\n",
        "\n",
        "    return new_text\n",
        "\n",
        "# Prompt the user for input\n",
        "original_text = texts\n",
        "print(\"original_text is :\" + original_text)\n",
        "word_to_replace = input(\"Enter the word you want replace it : \")\n",
        "replacement_word = input(\"Enter the replacement word : \")\n",
        "\n",
        "# Replace the word and get the modified text\n",
        "modified_text = replace_word(original_text, word_to_replace, replacement_word)\n",
        "\n",
        "print(\"Modified Text:\", modified_text)\n",
        "print(\"Modified word:\", replacement_word)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlxBiHzgSZ9E",
        "outputId": "a5ffa920-60d7-435f-8a98-37f5eb3d5282"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original_text is :happy Good Friday\n",
            "Enter the word you want replace it : Good\n",
            "Enter the replacement word : Bad\n",
            "Modified Text: happy Bad Friday\n",
            "Modified word: Bad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download the pretrained model to clone your voice with specific text"
      ],
      "metadata": {
        "id": "DRP25oRP4-qz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This will download all the models used by Tortoise from the HuggingFace hub.\n",
        "tts = TextToSpeech()"
      ],
      "metadata": {
        "id": "IWFiAS7_5CNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "def replace_word(text, word_to_replace, replacement):\n",
        "    # Split the input text into words\n",
        "    words = text.split()\n",
        "    \n",
        "    # Initialize an empty list to store the modified words\n",
        "    new_words = []\n",
        "\n",
        "    # Iterate through the words in the input text\n",
        "    for word in words:\n",
        "        # If the word matches the word to be replaced, use the replacement word\n",
        "        if word == word_to_replace:\n",
        "            new_words.append(replacement)\n",
        "        else:\n",
        "            new_words.append(word)\n",
        "\n",
        "    # Join the modified words to form the new text\n",
        "    new_text = \" \".join(new_words)\n",
        "    \n",
        "    return new_text\n",
        "\n",
        "# Prompt the user for input\n",
        "original_text = texts\n",
        "print(\"Original Text is:\" + original_text)\n",
        "word_to_replace = input(\"Enter the word you want to replace: \")\n",
        "replacement_word = input(\"Enter the replacement word: \")\n",
        "\n",
        "# Replace the word and get the modified text\n",
        "modified_text = replace_word(original_text, word_to_replace, replacement_word)\n",
        "\n",
        "print(\"Modified Text:\", modified_text)\n",
        "print(\"Modified Word:\", replacement_word)\n"
      ],
      "metadata": {
        "id": "7LDEIDf6RA0d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "def replace_word(text, word_to_replace, replacement):\n",
        "    # Find the starting and ending positions of the word to be replaced\n",
        "    word_start = text.find(word_to_replace)\n",
        "    word_end = word_start + len(word_to_replace)\n",
        "    \n",
        "    # Get the prefix and suffix parts of the text\n",
        "    prefix = text[:word_start]\n",
        "    suffix = text[word_end:]\n",
        "    \n",
        "    # Construct the modified text with the replacement word\n",
        "    modified_text = prefix + replacement + suffix\n",
        "    \n",
        "    return modified_text\n",
        "\n",
        "# Prompt the user for input\n",
        "original_text = texts\n",
        "print(\"Original Text is:\" + original_text)\n",
        "word_to_replace = input(\"Enter the word you want to replace: \")\n",
        "replacement_word = input(\"Enter the replacement word: \")\n",
        "\n",
        "# Replace the word and get the modified text\n",
        "modified_text = replace_word(original_text, word_to_replace, replacement_word)\n",
        "\n",
        "print(\"Modified Text:\", modified_text)\n",
        "print(\"Modified Word:\", replacement_word)"
      ],
      "metadata": {
        "id": "PtkJbge3X-A1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Detect the text and the quality of the voice clone"
      ],
      "metadata": {
        "id": "SBf9vm06V8Bm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the text that will be spoken.\n",
        "text = modified_text\n",
        "\n",
        "# Pick a \"preset mode\" to determine quality. Options: {\"ultra_fast\", \"fast\" (default), \"standard\", \"high_quality\"}. See docs in api.py\n",
        "preset = \"ultra_fast\""
      ],
      "metadata": {
        "id": "3JIMmUFr5HrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MOf9EDMea9Ku",
        "outputId": "3c54abe0-9937-4eb6-c964-8674478daa17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'happy Bad Friday'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload the voice that you want cloning it"
      ],
      "metadata": {
        "id": "_YFtSpvBWJKP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optionally, upload use your own voice by running the next two cells. I recommend\n",
        " you upload at least 2 audio clips. They must be a WAV file, 6-10 seconds long.\n",
        "CUSTOM_VOICE_NAME = \"ahmed2\"\n",
        "\n",
        "\n",
        "custom_voice_folder = f\"tortoise/voices/{CUSTOM_VOICE_NAME}\"\n",
        "os.makedirs(custom_voice_folder, exist_ok=True)\n",
        "for i, file_data in enumerate(files.upload().values()):\n",
        "  with open(os.path.join(custom_voice_folder, f'{i}.wav'), 'wb') as f:\n",
        "    f.write(file_data)"
      ],
      "metadata": {
        "id": "usY2M_3-5JKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "import torchaudio\n",
        "from IPython.display import Audio"
      ],
      "metadata": {
        "id": "sQcDEfZLRZpp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate speech with the custom voice.\n",
        "voice_samples, conditioning_latents = load_voice(CUSTOM_VOICE_NAME)\n",
        "gen = tts.tts_with_preset(text, voice_samples=voice_samples, conditioning_latents=conditioning_latents,\n",
        "                          preset=preset)\n",
        "#torchaudio.save(f'generated-{CUSTOM_VOICE_NAME}.wav', gen.squeeze(0).cpu(), 25000)\n",
        "torchaudio.save(f'generated-{CUSTOM_VOICE_NAME}.wav', gen.squeeze(0).cpu(), 25000)\n",
        "IPython.display.Audio(f'generated-{CUSTOM_VOICE_NAME}.wav')\n"
      ],
      "metadata": {
        "id": "bpFKaXVkRRir"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "original_audio, sample_rate = torchaudio.load(sounds)\n",
        "\n",
        "# Find the starting and ending sample positions of the replaced word\n",
        "word_to_replace_start = original_text.find(word_to_replace)\n",
        "word_to_replace_end = word_to_replace_start + len(word_to_replace)\n",
        "\n",
        "# Convert sample positions to frames\n",
        "frame_rate = sample_rate\n",
        "word_to_replace_start_frame = int(word_to_replace_start * frame_rate)\n",
        "word_to_replace_end_frame = int(word_to_replace_end * frame_rate)\n",
        "\n",
        "# Trim the original audio to exclude the replaced word\n",
        "trimmed_original_audio = original_audio[:, :word_to_replace_start_frame]\n"
      ],
      "metadata": {
        "id": "Bbl3IAEAU5zF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the original audio from the WAV file\n",
        "original_audio, sample_rate = torchaudio.load(sound)\n",
        "\n",
        "# Find the starting and ending sample positions of the word to be replaced\n",
        "word_to_replace_start = original_text.find(word_to_replace)\n",
        "word_to_replace_end = word_to_replace_start + len(word_to_replace)\n",
        "\n",
        "# Convert sample positions to frames\n",
        "frame_rate = sample_rate\n",
        "word_to_replace_start_frame = int(word_to_replace_start * frame_rate)\n",
        "word_to_replace_end_frame = int(word_to_replace_end * frame_rate)\n",
        "\n",
        "# Cut out the portion of the original audio corresponding to the word to be replaced\n",
        "trimmed_original_audio = original_audio[:, :word_to_replace_start_frame]\n"
      ],
      "metadata": {
        "id": "XLR4EeocYDFD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Play the generated audio, combining original and TTS parts\n",
        "original_audio, sample_rate = torchaudio.load(sounds)\n",
        "generated_audio = gen.squeeze(0)\n",
        "combined_audio = torch.cat((trimmed_original_audio, generated_audio, original_audio[:, word_to_replace_end_frame:]), dim=1)\n",
        "#combined_audio = torch.cat((original_audio, generated_audio), dim=1)\n",
        "torchaudio.save(f'combined-{CUSTOM_VOICE_NAME}.wav', combined_audio, 24000)\n",
        "Audio(f'combined-{CUSTOM_VOICE_NAME}.wav')"
      ],
      "metadata": {
        "id": "pNP3cAgkTtMb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate the Voice"
      ],
      "metadata": {
        "id": "tVqwGf7kWTC3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate speech with the custotm voice.\n",
        "voice_samples, conditioning_latents = load_voice(CUSTOM_VOICE_NAME)\n",
        "gen = tts.tts_with_preset(text, voice_samples=voice_samples, conditioning_latents=conditioning_latents,\n",
        "                          preset=preset)\n",
        "torchaudio.save(f'generated-{CUSTOM_VOICE_NAME}.wav', gen.squeeze(0).cpu(), 25000)\n",
        "IPython.display.Audio(f'generated-{CUSTOM_VOICE_NAME}.wav')"
      ],
      "metadata": {
        "id": "ssyj0huW5Kyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "CUSTOM_VOICE_NAME = \"ahmed1\"\n",
        "\n",
        "\n",
        "# Pick a \"preset mode\" to determine quality. Options: {\"ultra_fast\", \"fast\" (default), \"standard\", \"high_quality\"}. See docs in api.py\n",
        "preset = \"ultra_fast\"\n",
        "\n",
        "# Load the original audio from the WAV file\n",
        "original_audio, sample_rate = torchaudio.load(sounds)\n",
        "\n",
        "# Convert the original audio to mono if it's stereo\n",
        "if original_audio.shape[0] == 2:\n",
        "    original_audio = original_audio.mean(dim=0, keepdim=True)\n",
        "\n",
        "# Use the original text and the recognized text to find the position of the word to be replaced\n",
        "text_before = original_text.split(word_to_replace)[0]\n",
        "text_after = original_text.split(word_to_replace)[1]\n",
        "text_before_length = len(text_before)\n",
        "text_after_length = len(text_after)\n",
        "word_to_replace_start_frame = int((text_before_length / len(original_text)) * original_audio.shape[1])\n",
        "word_to_replace_end_frame = int(((text_before_length + len(word_to_replace)) / len(original_text)) * original_audio.shape[1])\n",
        "\n",
        "# Extract the audio before and after the word to be replaced\n",
        "audio_before = original_audio[:, :word_to_replace_start_frame]\n",
        "audio_after = original_audio[:, word_to_replace_end_frame:]\n",
        "\n",
        "# Optionally, upload use your own voice by running the next two cells. I recommend\n",
        "# you upload at least 2 audio clips. They must be a WAV file, 6-10 seconds long.\n",
        "custom_voice_folder = f\"tortoise/voices/{CUSTOM_VOICE_NAME}\"\n",
        "os.makedirs(custom_voice_folder, exist_ok=True)\n",
        "for i, file_data in enumerate(files.upload().values()):\n",
        "    with open(os.path.join(custom_voice_folder, f'{i}.wav'), 'wb') as f:\n",
        "        f.write(file_data)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "ajvb5F_C88gN",
        "outputId": "a67741c7-97bd-4b13-a41d-fde656f20c36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7172bc67-20a5-443d-b198-a4ad6157e6f2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7172bc67-20a5-443d-b198-a4ad6157e6f2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving scm_05223_01449581873.wav to scm_05223_01449581873 (1).wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate speech with the custom voice for the modified text\n",
        "voice_samples, conditioning_latents = load_voice(CUSTOM_VOICE_NAME)\n",
        "gen = tts.tts_with_preset(text, voice_samples=voice_samples, conditioning_latents=conditioning_latents,\n",
        "                          preset=preset)\n",
        "torchaudio.save(f'generated-{CUSTOM_VOICE_NAME}.wav', gen.squeeze(0).cpu(), 25000)\n",
        "IPython.display.Audio(f'generated-{CUSTOM_VOICE_NAME}.wav')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vvhhe2YVbYW4",
        "outputId": "55a98f8f-f3c1-43cd-bc9f-2040c717a1a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating autoregressive samples..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:03<00:00,  3.80s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing best candidates using CLVP and CVVP\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transforming autoregressive outputs into audio..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [00:00<00:00, 30.77it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "torchaudio.save(f'generated-{CUSTOM_VOICE_NAME}.wav', gen.squeeze(0).cpu(), 30000)"
      ],
      "metadata": {
        "id": "CedDaPh8ehYP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combine the audio_before, generated speech, and audio_after to create the final audio\n",
        "combined_audio = torch.cat((audio_before, gen.squeeze(0)), dim=1)\n",
        "torchaudio.save(f'combined-{CUSTOM_VOICE_NAME}.wav', combined_audio, 24000)\n"
      ],
      "metadata": {
        "id": "HISXCv7Wd0jH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Audio(f'combined-{CUSTOM_VOICE_NAME}.wav')\n"
      ],
      "metadata": {
        "id": "erqlAoNVcIOa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UaNLUbAAdofb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}